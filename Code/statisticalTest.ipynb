{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\mardi\\anaconda3\\lib\\site-packages (3.0.10)\n",
      "Requirement already satisfied: et_xmlfile in c:\\users\\mardi\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "!pip install openpyxl\n",
    "\n",
    "# Read the data from the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\mardi\\\\OneDrive - OUMail (Osaka University)\\\\Mardi's Files\\\\Research Topic and References\\\\Code\\\\Python Data\\\\statistical test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-posthocs\n",
      "  Obtaining dependency information for scikit-posthocs from https://files.pythonhosted.org/packages/7e/8f/a4d9542ea371be2a71abd4100e646cfc957d20871c4bc571b5f1d5d662c1/scikit_posthocs-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading scikit_posthocs-0.9.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\mardi\\anaconda3\\lib\\site-packages (from scikit-posthocs) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.9.0 in c:\\users\\mardi\\anaconda3\\lib\\site-packages (from scikit-posthocs) (1.11.1)\n",
      "Requirement already satisfied: statsmodels in c:\\users\\mardi\\anaconda3\\lib\\site-packages (from scikit-posthocs) (0.14.0)\n",
      "Requirement already satisfied: pandas>=0.20.0 in c:\\users\\mardi\\anaconda3\\lib\\site-packages (from scikit-posthocs) (2.0.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\mardi\\anaconda3\\lib\\site-packages (from scikit-posthocs) (0.12.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\mardi\\anaconda3\\lib\\site-packages (from scikit-posthocs) (3.7.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mardi\\anaconda3\\lib\\site-packages (from pandas>=0.20.0->scikit-posthocs) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mardi\\anaconda3\\lib\\site-packages (from pandas>=0.20.0->scikit-posthocs) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\mardi\\anaconda3\\lib\\site-packages (from pandas>=0.20.0->scikit-posthocs) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mardi\\anaconda3\\lib\\site-packages (from matplotlib->scikit-posthocs) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mardi\\anaconda3\\lib\\site-packages (from matplotlib->scikit-posthocs) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mardi\\anaconda3\\lib\\site-packages (from matplotlib->scikit-posthocs) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\mardi\\anaconda3\\lib\\site-packages (from matplotlib->scikit-posthocs) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mardi\\anaconda3\\lib\\site-packages (from matplotlib->scikit-posthocs) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\mardi\\anaconda3\\lib\\site-packages (from matplotlib->scikit-posthocs) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\mardi\\anaconda3\\lib\\site-packages (from matplotlib->scikit-posthocs) (3.0.9)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\mardi\\anaconda3\\lib\\site-packages (from statsmodels->scikit-posthocs) (0.5.3)\n",
      "Requirement already satisfied: six in c:\\users\\mardi\\anaconda3\\lib\\site-packages (from patsy>=0.5.2->statsmodels->scikit-posthocs) (1.16.0)\n",
      "Downloading scikit_posthocs-0.9.0-py3-none-any.whl (32 kB)\n",
      "Installing collected packages: scikit-posthocs\n",
      "Successfully installed scikit-posthocs-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-posthocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlsxwriter\n",
      "  Obtaining dependency information for xlsxwriter from https://files.pythonhosted.org/packages/a7/ea/53d1fe468e63e092cf16e2c18d16f50c29851242f9dd12d6a66e0d7f0d02/XlsxWriter-3.2.0-py3-none-any.whl.metadata\n",
      "  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
      "   ---------------------------------------- 0.0/159.9 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 30.7/159.9 kB 1.4 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 61.4/159.9 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 159.9/159.9 kB 1.6 MB/s eta 0:00:00\n",
      "Installing collected packages: xlsxwriter\n",
      "Successfully installed xlsxwriter-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DU_IBS1</th>\n",
       "      <th>U_IBS1</th>\n",
       "      <th>SU_IBS1</th>\n",
       "      <th>DU_IBS2</th>\n",
       "      <th>U_IBS2</th>\n",
       "      <th>DU_IBS3</th>\n",
       "      <th>U_IBS3</th>\n",
       "      <th>DU_PIC1</th>\n",
       "      <th>U_PIC1</th>\n",
       "      <th>DU_PIC2</th>\n",
       "      <th>...</th>\n",
       "      <th>SU_MAC2</th>\n",
       "      <th>R_MAC2</th>\n",
       "      <th>DU_MAC3</th>\n",
       "      <th>U_MAC3</th>\n",
       "      <th>SU_MAC3</th>\n",
       "      <th>R_MAC3</th>\n",
       "      <th>DU_MACHUB3</th>\n",
       "      <th>U_MACHUB3</th>\n",
       "      <th>SU_MACHUB3</th>\n",
       "      <th>R_MACHUB3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.136</td>\n",
       "      <td>4.136</td>\n",
       "      <td>3.848</td>\n",
       "      <td>4.656</td>\n",
       "      <td>4.368</td>\n",
       "      <td>6.641</td>\n",
       "      <td>5.530</td>\n",
       "      <td>3.368</td>\n",
       "      <td>2.408</td>\n",
       "      <td>2.736</td>\n",
       "      <td>...</td>\n",
       "      <td>3.347</td>\n",
       "      <td>4.499</td>\n",
       "      <td>4.378</td>\n",
       "      <td>5.414</td>\n",
       "      <td>3.898</td>\n",
       "      <td>3.898</td>\n",
       "      <td>9.244</td>\n",
       "      <td>7.530</td>\n",
       "      <td>7.606</td>\n",
       "      <td>8.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.040</td>\n",
       "      <td>2.888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.696</td>\n",
       "      <td>3.696</td>\n",
       "      <td>5.654</td>\n",
       "      <td>5.626</td>\n",
       "      <td>3.368</td>\n",
       "      <td>3.368</td>\n",
       "      <td>4.464</td>\n",
       "      <td>...</td>\n",
       "      <td>2.867</td>\n",
       "      <td>4.307</td>\n",
       "      <td>5.654</td>\n",
       "      <td>4.934</td>\n",
       "      <td>5.530</td>\n",
       "      <td>4.810</td>\n",
       "      <td>7.414</td>\n",
       "      <td>10.616</td>\n",
       "      <td>7.606</td>\n",
       "      <td>9.868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.848</td>\n",
       "      <td>2.408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.368</td>\n",
       "      <td>3.216</td>\n",
       "      <td>5.338</td>\n",
       "      <td>4.378</td>\n",
       "      <td>2.408</td>\n",
       "      <td>3.848</td>\n",
       "      <td>2.736</td>\n",
       "      <td>...</td>\n",
       "      <td>4.307</td>\n",
       "      <td>4.307</td>\n",
       "      <td>5.338</td>\n",
       "      <td>5.606</td>\n",
       "      <td>5.606</td>\n",
       "      <td>4.378</td>\n",
       "      <td>7.414</td>\n",
       "      <td>11.288</td>\n",
       "      <td>10.568</td>\n",
       "      <td>7.626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.328</td>\n",
       "      <td>3.224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.216</td>\n",
       "      <td>3.696</td>\n",
       "      <td>5.818</td>\n",
       "      <td>4.858</td>\n",
       "      <td>2.408</td>\n",
       "      <td>3.848</td>\n",
       "      <td>2.736</td>\n",
       "      <td>...</td>\n",
       "      <td>2.867</td>\n",
       "      <td>4.499</td>\n",
       "      <td>5.414</td>\n",
       "      <td>3.898</td>\n",
       "      <td>4.378</td>\n",
       "      <td>8.568</td>\n",
       "      <td>8.833</td>\n",
       "      <td>11.288</td>\n",
       "      <td>7.818</td>\n",
       "      <td>9.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.040</td>\n",
       "      <td>3.368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.216</td>\n",
       "      <td>3.696</td>\n",
       "      <td>8.108</td>\n",
       "      <td>6.833</td>\n",
       "      <td>3.368</td>\n",
       "      <td>3.368</td>\n",
       "      <td>2.736</td>\n",
       "      <td>...</td>\n",
       "      <td>2.867</td>\n",
       "      <td>3.827</td>\n",
       "      <td>3.974</td>\n",
       "      <td>3.974</td>\n",
       "      <td>4.454</td>\n",
       "      <td>5.654</td>\n",
       "      <td>10.108</td>\n",
       "      <td>7.530</td>\n",
       "      <td>11.384</td>\n",
       "      <td>8.418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DU_IBS1  U_IBS1  SU_IBS1  DU_IBS2  U_IBS2  DU_IBS3  U_IBS3  DU_PIC1  \\\n",
       "0    4.136   4.136    3.848    4.656   4.368    6.641   5.530    3.368   \n",
       "1    4.040   2.888      NaN    3.696   3.696    5.654   5.626    3.368   \n",
       "2    3.848   2.408      NaN    4.368   3.216    5.338   4.378    2.408   \n",
       "3    4.328   3.224      NaN    3.216   3.696    5.818   4.858    2.408   \n",
       "4    4.040   3.368      NaN    3.216   3.696    8.108   6.833    3.368   \n",
       "\n",
       "   U_PIC1  DU_PIC2  ...  SU_MAC2  R_MAC2  DU_MAC3  U_MAC3  SU_MAC3  R_MAC3  \\\n",
       "0   2.408    2.736  ...    3.347   4.499    4.378   5.414    3.898   3.898   \n",
       "1   3.368    4.464  ...    2.867   4.307    5.654   4.934    5.530   4.810   \n",
       "2   3.848    2.736  ...    4.307   4.307    5.338   5.606    5.606   4.378   \n",
       "3   3.848    2.736  ...    2.867   4.499    5.414   3.898    4.378   8.568   \n",
       "4   3.368    2.736  ...    2.867   3.827    3.974   3.974    4.454   5.654   \n",
       "\n",
       "   DU_MACHUB3  U_MACHUB3  SU_MACHUB3  R_MACHUB3  \n",
       "0       9.244      7.530       7.606      8.428  \n",
       "1       7.414     10.616       7.606      9.868  \n",
       "2       7.414     11.288      10.568      7.626  \n",
       "3       8.833     11.288       7.818      9.656  \n",
       "4      10.108      7.530      11.384      8.418  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DU_IBS1', 'U_IBS1', 'SU_IBS1', 'DU_IBS2', 'U_IBS2', 'DU_IBS3',\n",
       "       'U_IBS3', 'DU_PIC1', 'U_PIC1', 'DU_PIC2', 'U_PIC2', 'DU_PIC3', 'U_PIC3',\n",
       "       'DU_MIC1', 'U_MIC1', 'DU_MIC2', 'U_MIC2', 'SU_MIC2', 'DU_MIC3',\n",
       "       'U_MIC3', 'DU_MAC1', 'U_MAC1', 'SU_MAC1', 'R_MAC1', 'DU_MAC2', 'U_MAC2',\n",
       "       'SU_MAC2', 'R_MAC2', 'DU_MAC3', 'U_MAC3', 'SU_MAC3', 'R_MAC3',\n",
       "       'DU_MACHUB3', 'U_MACHUB3', 'SU_MACHUB3', 'R_MACHUB3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welch's t-test:\n",
      "t-statistic: 1.6822519808009162\n",
      "p-value: 0.09658346019216672\n",
      "Mann-Whitney U Test:\n",
      "U-statistic: 15334.0\n",
      "p-value: 0.2120653771924046\n"
     ]
    }
   ],
   "source": [
    "# Extract the data for two groups\n",
    "group1 = df['DU_IBS1'].dropna()\n",
    "group2 = df['U_IBS1'].dropna()\n",
    "\n",
    "# Perform Welch's t-test\n",
    "t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=False)\n",
    "\n",
    "# Print the results\n",
    "print(\"Welch's t-test:\")\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Store the results in a DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"Test\": [\"Welch's t-test\"],\n",
    "    \"Statistic\": [t_stat],\n",
    "    \"p-value\": [p_value]\n",
    "})\n",
    "\n",
    "# Perform Mann-Whitney U test\n",
    "u_stat, p_value = stats.mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "\n",
    "# Print the results\n",
    "print(\"Mann-Whitney U Test:\")\n",
    "print(\"U-statistic:\", u_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Create a DataFrame for the new results\n",
    "new_results = pd.DataFrame({\n",
    "    \"Test\": [\"Mann-Whitney U Test\"],\n",
    "    \"Statistic\": [u_stat],\n",
    "    \"p-value\": [p_value]\n",
    "})\n",
    "\n",
    "# Append the results to the DataFrame using concat\n",
    "results = pd.concat([results, new_results], ignore_index=True)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "results.to_excel(\"IBS1.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis H Test:\n",
      "H-statistic: 1.6748292864241838\n",
      "P-value: 0.4328280931970384\n",
      "The groups do not have significantly different medians.\n",
      "          group1    group2  group3\n",
      "group1  1.000000  0.635073     1.0\n",
      "group2  0.635073  1.000000     1.0\n",
      "group3  1.000000  1.000000     1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import numpy as np\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# Read the data from the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\mardi\\\\OneDrive - OUMail (Osaka University)\\\\Mardi's Files\\\\Research Topic and References\\\\Code\\\\Python Data\\\\statistical test.csv\")\n",
    "\n",
    "#Macro with 1 system configuration\n",
    "# Assuming your CSV file has columns named 'DU_MAC2', 'U_MAC2', 'SU_MAC2', R_MAC2'\n",
    "# Extract the data for each group\n",
    "group1 = df['DU_IBS1'].dropna()\n",
    "group2 = df['U_IBS1'].dropna()\n",
    "group3 = df['SU_IBS1'].dropna()\n",
    "\n",
    "# Ensure the data is numeric\n",
    "group1 = pd.to_numeric(group1, errors='coerce')\n",
    "group2 = pd.to_numeric(group2, errors='coerce')\n",
    "group3 = pd.to_numeric(group3, errors='coerce')\n",
    "\n",
    "# Perform Kruskal-Wallis test\n",
    "h_stat, p_value = stats.kruskal(group1, group2, group3)\n",
    "\n",
    "# Print the results\n",
    "print(\"Kruskal-Wallis H Test:\")\n",
    "print(\"H-statistic:\", h_stat)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"The groups have significantly different medians.\")\n",
    "else:\n",
    "    print(\"The groups do not have significantly different medians.\")\n",
    "\n",
    "\n",
    "# Concatenate the groups into a single data array\n",
    "data = pd.concat([group1, group2, group3])\n",
    "\n",
    "# Create a group array that identifies which group each data point belongs to\n",
    "groups = ['group1']*len(group1) + ['group2']*len(group2) + ['group3']*len(group3)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_posthoc = pd.DataFrame({'vals': data, 'group': groups})\n",
    "\n",
    "# Perform the Dunn's test\n",
    "dunn_results = sp.posthoc_dunn(df_posthoc, val_col='vals', group_col='group', p_adjust='holm')\n",
    "\n",
    "print(dunn_results)\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "results_df = pd.DataFrame({\n",
    "    \"Test\": [\"Kruskal-Wallis\"],\n",
    "    \"H-statistic\": [h_stat],\n",
    "    \"P-value\": [p_value],\n",
    "    \"Significance\": [\"Significant\" if p_value < alpha else \"Not Significant\"]\n",
    "})\n",
    "\n",
    "# Create a pandas Excel writer using XlsxWriter as the engine\n",
    "with pd.ExcelWriter(\"kruskal_wallis_IBS1.xlsx\", engine='xlsxwriter') as writer:\n",
    "    # Write the DataFrame to an Excel file\n",
    "    results_df.to_excel(writer, sheet_name='Kruskal-Wallis', index=False)\n",
    "\n",
    "    # Write the Dunn's test results to the same Excel file\n",
    "    dunn_results.to_excel(writer, sheet_name='Dunn', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welch's t-test:\n",
      "t-statistic: 0.5277104613466173\n",
      "p-value: 0.5991124911027732\n",
      "Mann-Whitney U Test:\n",
      "U-statistic: 6815.0\n",
      "p-value: 0.7783122438175092\n"
     ]
    }
   ],
   "source": [
    "# Extract the data for two groups\n",
    "group1 = df['DU_IBS2'].dropna()\n",
    "group2 = df['U_IBS2'].dropna()\n",
    "\n",
    "# Perform Welch's t-test\n",
    "t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=False)\n",
    "\n",
    "# Print the results\n",
    "print(\"Welch's t-test:\")\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Store the results in a DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"Test\": [\"Welch's t-test\"],\n",
    "    \"Statistic\": [t_stat],\n",
    "    \"p-value\": [p_value]\n",
    "})\n",
    "\n",
    "# Perform Mann-Whitney U test\n",
    "u_stat, p_value = stats.mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "\n",
    "# Print the results\n",
    "print(\"Mann-Whitney U Test:\")\n",
    "print(\"U-statistic:\", u_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Create a DataFrame for the new results\n",
    "new_results = pd.DataFrame({\n",
    "    \"Test\": [\"Mann-Whitney U Test\"],\n",
    "    \"Statistic\": [u_stat],\n",
    "    \"p-value\": [p_value]\n",
    "})\n",
    "\n",
    "# Append the results to the DataFrame using concat\n",
    "results = pd.concat([results, new_results], ignore_index=True)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "results.to_excel(\"IBS2.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welch's t-test:\n",
      "t-statistic: 1.381242341689982\n",
      "p-value: 0.17818886549842822\n",
      "Mann-Whitney U Test:\n",
      "U-statistic: 234.5\n",
      "p-value: 0.365310025247906\n"
     ]
    }
   ],
   "source": [
    "# Extract the data for two groups\n",
    "group1 = df['DU_IBS3'].dropna()\n",
    "group2 = df['U_IBS3'].dropna()\n",
    "\n",
    "# Perform Welch's t-test\n",
    "t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=False)\n",
    "\n",
    "# Print the results\n",
    "print(\"Welch's t-test:\")\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Store the results in a DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"Test\": [\"Welch's t-test\"],\n",
    "    \"Statistic\": [t_stat],\n",
    "    \"p-value\": [p_value]\n",
    "})\n",
    "\n",
    "# Perform Mann-Whitney U test\n",
    "u_stat, p_value = stats.mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "\n",
    "# Print the results\n",
    "print(\"Mann-Whitney U Test:\")\n",
    "print(\"U-statistic:\", u_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Create a DataFrame for the new results\n",
    "new_results = pd.DataFrame({\n",
    "    \"Test\": [\"Mann-Whitney U Test\"],\n",
    "    \"Statistic\": [u_stat],\n",
    "    \"p-value\": [p_value]\n",
    "})\n",
    "\n",
    "# Append the results to the DataFrame using concat\n",
    "results = pd.concat([results, new_results], ignore_index=True)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "results.to_excel(\"IBS3.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welch's t-test:\n",
      "t-statistic: -0.6810816074449754\n",
      "p-value: 0.505702237370674\n",
      "Mann-Whitney U Test:\n",
      "U-statistic: 67.0\n",
      "p-value: 0.47058590744449846\n"
     ]
    }
   ],
   "source": [
    "# Extract the data for two groups\n",
    "group1 = df['DU_PIC1'].dropna()\n",
    "group2 = df['U_PIC1'].dropna()\n",
    "\n",
    "# Perform Welch's t-test\n",
    "t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=False)\n",
    "\n",
    "# Print the results\n",
    "print(\"Welch's t-test:\")\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Store the results in a DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"Test\": [\"Welch's t-test\"],\n",
    "    \"Statistic\": [t_stat],\n",
    "    \"p-value\": [p_value]\n",
    "})\n",
    "\n",
    "# Perform Mann-Whitney U test\n",
    "u_stat, p_value = stats.mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "\n",
    "# Print the results\n",
    "print(\"Mann-Whitney U Test:\")\n",
    "print(\"U-statistic:\", u_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Create a DataFrame for the new results\n",
    "new_results = pd.DataFrame({\n",
    "    \"Test\": [\"Mann-Whitney U Test\"],\n",
    "    \"Statistic\": [u_stat],\n",
    "    \"p-value\": [p_value]\n",
    "})\n",
    "\n",
    "# Append the results to the DataFrame using concat\n",
    "results = pd.concat([results, new_results], ignore_index=True)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "results.to_excel(\"PIC1.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welch's t-test:\n",
      "t-statistic: -0.33237849545561915\n",
      "p-value: 0.7444568383802388\n",
      "Mann-Whitney U Test:\n",
      "U-statistic: 69.5\n",
      "p-value: 0.9014292584696411\n"
     ]
    }
   ],
   "source": [
    "# Extract the data for two groups\n",
    "group1 = df['DU_PIC2'].dropna()\n",
    "group2 = df['U_PIC2'].dropna()\n",
    "\n",
    "# Perform Welch's t-test\n",
    "t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=False)\n",
    "\n",
    "# Print the results\n",
    "print(\"Welch's t-test:\")\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Store the results in a DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"Test\": [\"Welch's t-test\"],\n",
    "    \"Statistic\": [t_stat],\n",
    "    \"p-value\": [p_value]\n",
    "})\n",
    "\n",
    "# Perform Mann-Whitney U test\n",
    "u_stat, p_value = stats.mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "\n",
    "# Print the results\n",
    "print(\"Mann-Whitney U Test:\")\n",
    "print(\"U-statistic:\", u_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Create a DataFrame for the new results\n",
    "new_results = pd.DataFrame({\n",
    "    \"Test\": [\"Mann-Whitney U Test\"],\n",
    "    \"Statistic\": [u_stat],\n",
    "    \"p-value\": [p_value]\n",
    "})\n",
    "\n",
    "# Append the results to the DataFrame using concat\n",
    "results = pd.concat([results, new_results], ignore_index=True)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "results.to_excel(\"PIC2.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welch's t-test:\n",
      "t-statistic: nan\n",
      "p-value: nan\n",
      "Mann-Whitney U Test:\n",
      "U-statistic: 1.0\n",
      "p-value: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mardi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\stats\\_stats_py.py:1081: RuntimeWarning: divide by zero encountered in divide\n",
      "  var *= np.divide(n, n-ddof)  # to avoid error on division by zero\n",
      "C:\\Users\\mardi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\stats\\_stats_py.py:1081: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  var *= np.divide(n, n-ddof)  # to avoid error on division by zero\n"
     ]
    }
   ],
   "source": [
    "# Extract the data for two groups\n",
    "group1 = df['DU_PIC3'].dropna()\n",
    "group2 = df['U_PIC3'].dropna()\n",
    "\n",
    "# Perform Welch's t-test\n",
    "t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=False)\n",
    "\n",
    "# Print the results\n",
    "print(\"Welch's t-test:\")\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Store the results in a DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"Test\": [\"Welch's t-test\"],\n",
    "    \"Statistic\": [t_stat],\n",
    "    \"p-value\": [p_value]\n",
    "})\n",
    "\n",
    "# Perform Mann-Whitney U test\n",
    "u_stat, p_value = stats.mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "\n",
    "# Print the results\n",
    "print(\"Mann-Whitney U Test:\")\n",
    "print(\"U-statistic:\", u_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Create a DataFrame for the new results\n",
    "new_results = pd.DataFrame({\n",
    "    \"Test\": [\"Mann-Whitney U Test\"],\n",
    "    \"Statistic\": [u_stat],\n",
    "    \"p-value\": [p_value]\n",
    "})\n",
    "\n",
    "# Append the results to the DataFrame using concat\n",
    "results = pd.concat([results, new_results], ignore_index=True)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "results.to_excel(\"PIC3.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welch's t-test:\n",
      "t-statistic: 1.0482341610134613\n",
      "p-value: 0.29679400983246373\n",
      "Mann-Whitney U Test:\n",
      "U-statistic: 2600.5\n",
      "p-value: 0.49760964851065914\n"
     ]
    }
   ],
   "source": [
    "# Extract the data for two groups\n",
    "group1 = df['DU_MIC1'].dropna()\n",
    "group2 = df['U_MIC1'].dropna()\n",
    "\n",
    "# Perform Welch's t-test\n",
    "t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=False)\n",
    "\n",
    "# Print the results\n",
    "print(\"Welch's t-test:\")\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Store the results in a DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"Test\": [\"Welch's t-test\"],\n",
    "    \"Statistic\": [t_stat],\n",
    "    \"p-value\": [p_value]\n",
    "})\n",
    "\n",
    "# Perform Mann-Whitney U test\n",
    "u_stat, p_value = stats.mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "\n",
    "# Print the results\n",
    "print(\"Mann-Whitney U Test:\")\n",
    "print(\"U-statistic:\", u_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Create a DataFrame for the new results\n",
    "new_results = pd.DataFrame({\n",
    "    \"Test\": [\"Mann-Whitney U Test\"],\n",
    "    \"Statistic\": [u_stat],\n",
    "    \"p-value\": [p_value]\n",
    "})\n",
    "\n",
    "# Append the results to the DataFrame using concat\n",
    "results = pd.concat([results, new_results], ignore_index=True)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "results.to_excel(\"MIC1.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welch's t-test:\n",
      "t-statistic: 0.48095490717090367\n",
      "p-value: 0.6315256281746846\n",
      "Mann-Whitney U Test:\n",
      "U-statistic: 1501.0\n",
      "p-value: 0.7991192460887836\n"
     ]
    }
   ],
   "source": [
    "# Extract the data for two groups\n",
    "group1 = df['DU_MIC2'].dropna()\n",
    "group2 = df['U_MIC2'].dropna()\n",
    "\n",
    "# Perform Welch's t-test\n",
    "t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=False)\n",
    "\n",
    "# Print the results\n",
    "print(\"Welch's t-test:\")\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Store the results in a DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"Test\": [\"Welch's t-test\"],\n",
    "    \"Statistic\": [t_stat],\n",
    "    \"p-value\": [p_value]\n",
    "})\n",
    "\n",
    "# Perform Mann-Whitney U test\n",
    "u_stat, p_value = stats.mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "\n",
    "# Print the results\n",
    "print(\"Mann-Whitney U Test:\")\n",
    "print(\"U-statistic:\", u_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Create a DataFrame for the new results\n",
    "new_results = pd.DataFrame({\n",
    "    \"Test\": [\"Mann-Whitney U Test\"],\n",
    "    \"Statistic\": [u_stat],\n",
    "    \"p-value\": [p_value]\n",
    "})\n",
    "\n",
    "# Append the results to the DataFrame using concat\n",
    "results = pd.concat([results, new_results], ignore_index=True)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "results.to_excel(\"MIC2.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis H Test:\n",
      "H-statistic: 0.10571468952490463\n",
      "P-value: 0.9485153135087349\n",
      "The groups do not have significantly different medians.\n",
      "        group1  group2  group3\n",
      "group1     1.0     1.0     1.0\n",
      "group2     1.0     1.0     1.0\n",
      "group3     1.0     1.0     1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import numpy as np\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# Read the data from the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\mardi\\\\OneDrive - OUMail (Osaka University)\\\\Mardi's Files\\\\Research Topic and References\\\\Code\\\\Python Data\\\\statistical test.csv\")\n",
    "\n",
    "#Macro with 1 system configuration\n",
    "# Assuming your CSV file has columns named 'DU_MAC2', 'U_MAC2', 'SU_MAC2', R_MAC2'\n",
    "# Extract the data for each group\n",
    "group1 = df['DU_MIC2'].dropna()\n",
    "group2 = df['U_MIC2'].dropna()\n",
    "group3 = df['SU_MIC2'].dropna()\n",
    "\n",
    "# Ensure the data is numeric\n",
    "group1 = pd.to_numeric(group1, errors='coerce')\n",
    "group2 = pd.to_numeric(group2, errors='coerce')\n",
    "group3 = pd.to_numeric(group3, errors='coerce')\n",
    "\n",
    "# Perform Kruskal-Wallis test\n",
    "h_stat, p_value = stats.kruskal(group1, group2, group3)\n",
    "\n",
    "# Print the results\n",
    "print(\"Kruskal-Wallis H Test:\")\n",
    "print(\"H-statistic:\", h_stat)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"The groups have significantly different medians.\")\n",
    "else:\n",
    "    print(\"The groups do not have significantly different medians.\")\n",
    "\n",
    "\n",
    "# Concatenate the groups into a single data array\n",
    "data = pd.concat([group1, group2, group3])\n",
    "\n",
    "# Create a group array that identifies which group each data point belongs to\n",
    "groups = ['group1']*len(group1) + ['group2']*len(group2) + ['group3']*len(group3)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_posthoc = pd.DataFrame({'vals': data, 'group': groups})\n",
    "\n",
    "# Perform the Dunn's test\n",
    "dunn_results = sp.posthoc_dunn(df_posthoc, val_col='vals', group_col='group', p_adjust='holm')\n",
    "\n",
    "print(dunn_results)\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "results_df = pd.DataFrame({\n",
    "    \"Test\": [\"Kruskal-Wallis\"],\n",
    "    \"H-statistic\": [h_stat],\n",
    "    \"P-value\": [p_value],\n",
    "    \"Significance\": [\"Significant\" if p_value < alpha else \"Not Significant\"]\n",
    "})\n",
    "\n",
    "# Create a pandas Excel writer using XlsxWriter as the engine\n",
    "with pd.ExcelWriter(\"kruskal_wallis_MIC2.xlsx\", engine='xlsxwriter') as writer:\n",
    "    # Write the DataFrame to an Excel file\n",
    "    results_df.to_excel(writer, sheet_name='Kruskal-Wallis', index=False)\n",
    "\n",
    "    # Write the Dunn's test results to the same Excel file\n",
    "    dunn_results.to_excel(writer, sheet_name='Dunn', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welch's t-test:\n",
      "t-statistic: -0.6447689978425328\n",
      "p-value: 0.5263379898810858\n",
      "Mann-Whitney U Test:\n",
      "U-statistic: 123.5\n",
      "p-value: 0.30782373507002747\n"
     ]
    }
   ],
   "source": [
    "# Extract the data for two groups\n",
    "group1 = df['DU_MIC3'].dropna()\n",
    "group2 = df['U_MIC3'].dropna()\n",
    "\n",
    "# Perform Welch's t-test\n",
    "t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=False)\n",
    "\n",
    "# Print the results\n",
    "print(\"Welch's t-test:\")\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Store the results in a DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"Test\": [\"Welch's t-test\"],\n",
    "    \"Statistic\": [t_stat],\n",
    "    \"p-value\": [p_value]\n",
    "})\n",
    "\n",
    "# Perform Mann-Whitney U test\n",
    "u_stat, p_value = stats.mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "\n",
    "# Print the results\n",
    "print(\"Mann-Whitney U Test:\")\n",
    "print(\"U-statistic:\", u_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Create a DataFrame for the new results\n",
    "new_results = pd.DataFrame({\n",
    "    \"Test\": [\"Mann-Whitney U Test\"],\n",
    "    \"Statistic\": [u_stat],\n",
    "    \"p-value\": [p_value]\n",
    "})\n",
    "\n",
    "# Append the results to the DataFrame using concat\n",
    "results = pd.concat([results, new_results], ignore_index=True)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "results.to_excel(\"MIC3.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-posthocs\n",
      "  Downloading scikit_posthocs-0.9.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\mardi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-posthocs) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.9.0 in c:\\users\\mardi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-posthocs) (1.12.0)\n",
      "Requirement already satisfied: statsmodels in c:\\users\\mardi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-posthocs) (0.14.1)\n",
      "Requirement already satisfied: pandas>=0.20.0 in c:\\users\\mardi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-posthocs) (2.2.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\mardi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-posthocs) (0.13.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\mardi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-posthocs) (3.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mardi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=0.20.0->scikit-posthocs) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mardi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=0.20.0->scikit-posthocs) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mardi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=0.20.0->scikit-posthocs) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mardi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->scikit-posthocs) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mardi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->scikit-posthocs) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mardi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->scikit-posthocs) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\mardi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->scikit-posthocs) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mardi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->scikit-posthocs) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\mardi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->scikit-posthocs) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\mardi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->scikit-posthocs) (3.1.1)\n",
      "Requirement already satisfied: patsy>=0.5.4 in c:\\users\\mardi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from statsmodels->scikit-posthocs) (0.5.6)\n",
      "Requirement already satisfied: six in c:\\users\\mardi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from patsy>=0.5.4->statsmodels->scikit-posthocs) (1.16.0)\n",
      "Downloading scikit_posthocs-0.9.0-py3-none-any.whl (32 kB)\n",
      "Installing collected packages: scikit-posthocs\n",
      "Successfully installed scikit-posthocs-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-posthocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlsxwriter\n",
      "  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
      "   ---------------------------------------- 0.0/159.9 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/159.9 kB ? eta -:--:--\n",
      "   ------- ------------------------------- 30.7/159.9 kB 325.1 kB/s eta 0:00:01\n",
      "   ---------------------- ---------------- 92.2/159.9 kB 744.7 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 122.9/159.9 kB 798.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 153.6/159.9 kB 762.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- 159.9/159.9 kB 683.5 kB/s eta 0:00:00\n",
      "Installing collected packages: xlsxwriter\n",
      "Successfully installed xlsxwriter-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\mardi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\mardi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mardi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mardi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mardi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mardi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: xlsxwriter in c:\\users\\mardi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pandas\n",
    "!pip install --upgrade xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis H Test:\n",
      "H-statistic: 9.16697597875139\n",
      "P-value: 0.02715128521720688\n",
      "The groups have significantly different medians.\n",
      "          group1    group2    group3    group4\n",
      "group1  1.000000  0.055649  0.359339  0.519746\n",
      "group2  0.055649  1.000000  1.000000  1.000000\n",
      "group3  0.359339  1.000000  1.000000  1.000000\n",
      "group4  0.519746  1.000000  1.000000  1.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import numpy as np\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# Read the data from the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\mardi\\\\OneDrive - OUMail (Osaka University)\\\\Mardi's Files\\\\Research Topic and References\\\\Code\\\\Python Data\\\\statistical test.csv\")\n",
    "\n",
    "#Macro with 1 system configuration\n",
    "# Assuming your CSV file has columns named 'DU_MAC2', 'U_MAC2', 'SU_MAC2', R_MAC2'\n",
    "# Extract the data for each group\n",
    "group1 = df['DU_MAC1'].dropna()\n",
    "group2 = df['U_MAC1'].dropna()\n",
    "group3 = df['SU_MAC1'].dropna()\n",
    "group4 = df['R_MAC1'].dropna()\n",
    "\n",
    "# Ensure the data is numeric\n",
    "group1 = pd.to_numeric(group1, errors='coerce')\n",
    "group2 = pd.to_numeric(group2, errors='coerce')\n",
    "group3 = pd.to_numeric(group3, errors='coerce')\n",
    "group4 = pd.to_numeric(group4, errors='coerce')\n",
    "\n",
    "# Perform Kruskal-Wallis test\n",
    "h_stat, p_value = stats.kruskal(group1, group2, group3, group4)\n",
    "\n",
    "# Print the results\n",
    "print(\"Kruskal-Wallis H Test:\")\n",
    "print(\"H-statistic:\", h_stat)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"The groups have significantly different medians.\")\n",
    "else:\n",
    "    print(\"The groups do not have significantly different medians.\")\n",
    "\n",
    "\n",
    "# Concatenate the groups into a single data array\n",
    "data = pd.concat([group1, group2, group3, group4])\n",
    "\n",
    "# Create a group array that identifies which group each data point belongs to\n",
    "groups = ['group1']*len(group1) + ['group2']*len(group2) + ['group3']*len(group3) + ['group4']*len(group4)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_posthoc = pd.DataFrame({'vals': data, 'group': groups})\n",
    "\n",
    "# Perform the Dunn's test\n",
    "dunn_results = sp.posthoc_dunn(df_posthoc, val_col='vals', group_col='group', p_adjust='holm')\n",
    "\n",
    "print(dunn_results)\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "results_df = pd.DataFrame({\n",
    "    \"Test\": [\"Kruskal-Wallis\"],\n",
    "    \"H-statistic\": [h_stat],\n",
    "    \"P-value\": [p_value],\n",
    "    \"Significance\": [\"Significant\" if p_value < alpha else \"Not Significant\"]\n",
    "})\n",
    "\n",
    "# Create a pandas Excel writer using XlsxWriter as the engine\n",
    "with pd.ExcelWriter(\"kruskal_wallis_MAC1.xlsx\", engine='xlsxwriter') as writer:\n",
    "    # Write the DataFrame to an Excel file\n",
    "    results_df.to_excel(writer, sheet_name='Kruskal-Wallis', index=False)\n",
    "\n",
    "    # Write the Dunn's test results to the same Excel file\n",
    "    dunn_results.to_excel(writer, sheet_name='Dunn', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis H Test:\n",
      "H-statistic: 32.63134179598637\n",
      "P-value: 3.852093468707609e-07\n",
      "The groups have significantly different medians.\n",
      "          group1    group2    group3    group4\n",
      "group1  1.000000  0.000204  0.278650  0.218099\n",
      "group2  0.000204  1.000000  0.000204  0.002506\n",
      "group3  0.278650  0.000204  1.000000  0.426806\n",
      "group4  0.218099  0.002506  0.426806  1.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import numpy as np\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# Read the data from the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\mardi\\\\OneDrive - OUMail (Osaka University)\\\\Mardi's Files\\\\Research Topic and References\\\\Code\\\\Python Data\\\\statistical test.csv\")\n",
    "\n",
    "#Macro with 1 system configuration\n",
    "# Assuming your CSV file has columns named 'DU_MAC2', 'U_MAC2', 'SU_MAC2', R_MAC2'\n",
    "# Extract the data for each group\n",
    "group1 = df['DU_MAC2'].dropna()\n",
    "group2 = df['U_MAC2'].dropna()\n",
    "group3 = df['SU_MAC2'].dropna()\n",
    "group4 = df['R_MAC2'].dropna()\n",
    "\n",
    "# Ensure the data is numeric\n",
    "group1 = pd.to_numeric(group1, errors='coerce')\n",
    "group2 = pd.to_numeric(group2, errors='coerce')\n",
    "group3 = pd.to_numeric(group3, errors='coerce')\n",
    "group4 = pd.to_numeric(group4, errors='coerce')\n",
    "\n",
    "# Perform Kruskal-Wallis test\n",
    "h_stat, p_value = stats.kruskal(group1, group2, group3, group4)\n",
    "\n",
    "# Print the results\n",
    "print(\"Kruskal-Wallis H Test:\")\n",
    "print(\"H-statistic:\", h_stat)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"The groups have significantly different medians.\")\n",
    "else:\n",
    "    print(\"The groups do not have significantly different medians.\")\n",
    "\n",
    "\n",
    "# Concatenate the groups into a single data array\n",
    "data = pd.concat([group1, group2, group3, group4])\n",
    "\n",
    "# Create a group array that identifies which group each data point belongs to\n",
    "groups = ['group1']*len(group1) + ['group2']*len(group2) + ['group3']*len(group3) + ['group4']*len(group4)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_posthoc = pd.DataFrame({'vals': data, 'group': groups})\n",
    "\n",
    "# Perform the Dunn's test\n",
    "dunn_results = sp.posthoc_dunn(df_posthoc, val_col='vals', group_col='group', p_adjust='holm')\n",
    "\n",
    "print(dunn_results)\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "results_df = pd.DataFrame({\n",
    "    \"Test\": [\"Kruskal-Wallis\"],\n",
    "    \"H-statistic\": [h_stat],\n",
    "    \"P-value\": [p_value],\n",
    "    \"Significance\": [\"Significant\" if p_value < alpha else \"Not Significant\"]\n",
    "})\n",
    "\n",
    "# Create a pandas Excel writer using XlsxWriter as the engine\n",
    "with pd.ExcelWriter(\"kruskal_wallis_MAC2.xlsx\", engine='xlsxwriter') as writer:\n",
    "    # Write the DataFrame to an Excel file\n",
    "    results_df.to_excel(writer, sheet_name='Kruskal-Wallis', index=False)\n",
    "\n",
    "    # Write the Dunn's test results to the same Excel file\n",
    "    dunn_results.to_excel(writer, sheet_name='Dunn', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis H Test:\n",
      "H-statistic: 8.629637047793258\n",
      "P-value: 0.034642717517775666\n",
      "The groups have significantly different medians.\n",
      "          group1    group2  group3  group4\n",
      "group1  1.000000  0.022863     1.0     1.0\n",
      "group2  0.022863  1.000000     1.0     1.0\n",
      "group3  1.000000  1.000000     1.0     1.0\n",
      "group4  1.000000  1.000000     1.0     1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import numpy as np\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# Read the data from the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\mardi\\\\OneDrive - OUMail (Osaka University)\\\\Mardi's Files\\\\Research Topic and References\\\\Code\\\\Python Data\\\\statistical test.csv\")\n",
    "\n",
    "#Macro with 1 system configuration\n",
    "# Assuming your CSV file has columns named 'DU_MAC2', 'U_MAC2', 'SU_MAC2', R_MAC2'\n",
    "# Extract the data for each group\n",
    "group1 = df['DU_MAC3'].dropna()\n",
    "group2 = df['U_MAC3'].dropna()\n",
    "group3 = df['SU_MAC3'].dropna()\n",
    "group4 = df['R_MAC3'].dropna()\n",
    "\n",
    "# Ensure the data is numeric\n",
    "group1 = pd.to_numeric(group1, errors='coerce')\n",
    "group2 = pd.to_numeric(group2, errors='coerce')\n",
    "group3 = pd.to_numeric(group3, errors='coerce')\n",
    "group4 = pd.to_numeric(group4, errors='coerce')\n",
    "\n",
    "# Perform Kruskal-Wallis test\n",
    "h_stat, p_value = stats.kruskal(group1, group2, group3, group4)\n",
    "\n",
    "# Print the results\n",
    "print(\"Kruskal-Wallis H Test:\")\n",
    "print(\"H-statistic:\", h_stat)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"The groups have significantly different medians.\")\n",
    "else:\n",
    "    print(\"The groups do not have significantly different medians.\")\n",
    "\n",
    "\n",
    "# Concatenate the groups into a single data array\n",
    "data = pd.concat([group1, group2, group3, group4])\n",
    "\n",
    "# Create a group array that identifies which group each data point belongs to\n",
    "groups = ['group1']*len(group1) + ['group2']*len(group2) + ['group3']*len(group3) + ['group4']*len(group4)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_posthoc = pd.DataFrame({'vals': data, 'group': groups})\n",
    "\n",
    "# Perform the Dunn's test\n",
    "dunn_results = sp.posthoc_dunn(df_posthoc, val_col='vals', group_col='group', p_adjust='holm')\n",
    "\n",
    "print(dunn_results)\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "results_df = pd.DataFrame({\n",
    "    \"Test\": [\"Kruskal-Wallis\"],\n",
    "    \"H-statistic\": [h_stat],\n",
    "    \"P-value\": [p_value],\n",
    "    \"Significance\": [\"Significant\" if p_value < alpha else \"Not Significant\"]\n",
    "})\n",
    "\n",
    "# Create a pandas Excel writer using XlsxWriter as the engine\n",
    "with pd.ExcelWriter(\"kruskal_wallis_MAC3.xlsx\", engine='xlsxwriter') as writer:\n",
    "    # Write the DataFrame to an Excel file\n",
    "    results_df.to_excel(writer, sheet_name='Kruskal-Wallis', index=False)\n",
    "\n",
    "    # Write the Dunn's test results to the same Excel file\n",
    "    dunn_results.to_excel(writer, sheet_name='Dunn', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis H Test:\n",
      "H-statistic: 14.477228673226156\n",
      "P-value: 0.0023225470405585638\n",
      "The groups have significantly different medians.\n",
      "          group1    group2    group3  group4\n",
      "group1  1.000000  0.001453  0.349654     1.0\n",
      "group2  0.001453  1.000000  1.000000     1.0\n",
      "group3  0.349654  1.000000  1.000000     1.0\n",
      "group4  1.000000  1.000000  1.000000     1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import numpy as np\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# Read the data from the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\mardi\\\\OneDrive - OUMail (Osaka University)\\\\Mardi's Files\\\\Research Topic and References\\\\Code\\\\Python Data\\\\statistical test.csv\")\n",
    "\n",
    "#Macro with 1 system configuration\n",
    "# Assuming your CSV file has columns named 'DU_MAC2', 'U_MAC2', 'SU_MAC2', R_MAC2'\n",
    "# Extract the data for each group\n",
    "group1 = df['DU_MACHUB3'].dropna()\n",
    "group2 = df['U_MACHUB3'].dropna()\n",
    "group3 = df['SU_MACHUB3'].dropna()\n",
    "group4 = df['R_MACHUB3'].dropna()\n",
    "\n",
    "# Ensure the data is numeric\n",
    "group1 = pd.to_numeric(group1, errors='coerce')\n",
    "group2 = pd.to_numeric(group2, errors='coerce')\n",
    "group3 = pd.to_numeric(group3, errors='coerce')\n",
    "group4 = pd.to_numeric(group4, errors='coerce')\n",
    "\n",
    "# Perform Kruskal-Wallis test\n",
    "h_stat, p_value = stats.kruskal(group1, group2, group3, group4)\n",
    "\n",
    "# Print the results\n",
    "print(\"Kruskal-Wallis H Test:\")\n",
    "print(\"H-statistic:\", h_stat)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"The groups have significantly different medians.\")\n",
    "else:\n",
    "    print(\"The groups do not have significantly different medians.\")\n",
    "\n",
    "\n",
    "# Concatenate the groups into a single data array\n",
    "data = pd.concat([group1, group2, group3, group4])\n",
    "\n",
    "# Create a group array that identifies which group each data point belongs to\n",
    "groups = ['group1']*len(group1) + ['group2']*len(group2) + ['group3']*len(group3) + ['group4']*len(group4)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_posthoc = pd.DataFrame({'vals': data, 'group': groups})\n",
    "\n",
    "# Perform the Dunn's test\n",
    "dunn_results = sp.posthoc_dunn(df_posthoc, val_col='vals', group_col='group', p_adjust='holm')\n",
    "\n",
    "print(dunn_results)\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "results_df = pd.DataFrame({\n",
    "    \"Test\": [\"Kruskal-Wallis\"],\n",
    "    \"H-statistic\": [h_stat],\n",
    "    \"P-value\": [p_value],\n",
    "    \"Significance\": [\"Significant\" if p_value < alpha else \"Not Significant\"]\n",
    "})\n",
    "\n",
    "# Create a pandas Excel writer using XlsxWriter as the engine\n",
    "with pd.ExcelWriter(\"kruskal_wallis_MACHUB3.xlsx\", engine='xlsxwriter') as writer:\n",
    "    # Write the DataFrame to an Excel file\n",
    "    results_df.to_excel(writer, sheet_name='Kruskal-Wallis', index=False)\n",
    "\n",
    "    # Write the Dunn's test results to the same Excel file\n",
    "    dunn_results.to_excel(writer, sheet_name='Dunn', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second Stage Comparison (between BTS segment with average peak power consumption very near to each other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DU_IBS1', 'U_IBS1', 'SU_IBS1', 'DU_IBS2', 'U_IBS2', 'DU_IBS3',\n",
       "       'U_IBS3', 'DU_PIC1', 'U_PIC1', 'DU_PIC2', 'U_PIC2', 'DU_PIC3', 'U_PIC3',\n",
       "       'DU_MIC1', 'U_MIC1', 'DU_MIC2', 'U_MIC2', 'SU_MIC2', 'DU_MIC3',\n",
       "       'U_MIC3', 'DU_MAC1', 'U_MAC1', 'SU_MAC1', 'R_MAC1', 'DU_MAC2', 'U_MAC2',\n",
       "       'SU_MAC2', 'R_MAC2', 'DU_MAC3', 'U_MAC3', 'SU_MAC3', 'R_MAC3',\n",
       "       'DU_MACHUB3', 'U_MACHUB3', 'SU_MACHUB3', 'R_MACHUB3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welch's t-test:\n",
      "t-statistic: 0.06898052944299198\n",
      "p-value: 0.9454213841930816\n",
      "Mann-Whitney U Test:\n",
      "U-statistic: 162.0\n",
      "p-value: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Extract the data for two groups\n",
    "group1 = df['DU_PIC1'].dropna()\n",
    "group2 = df['DU_PIC2'].dropna()\n",
    "\n",
    "# Perform Welch's t-test\n",
    "t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=False)\n",
    "\n",
    "# Print the results\n",
    "print(\"Welch's t-test:\")\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Store the results in a DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"Test\": [\"Welch's t-test\"],\n",
    "    \"Statistic\": [t_stat],\n",
    "    \"p-value\": [p_value]\n",
    "})\n",
    "\n",
    "# Perform Mann-Whitney U test\n",
    "u_stat, p_value = stats.mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "\n",
    "# Print the results\n",
    "print(\"Mann-Whitney U Test:\")\n",
    "print(\"U-statistic:\", u_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Create a DataFrame for the new results\n",
    "new_results = pd.DataFrame({\n",
    "    \"Test\": [\"Mann-Whitney U Test\"],\n",
    "    \"Statistic\": [u_stat],\n",
    "    \"p-value\": [p_value]\n",
    "})\n",
    "\n",
    "# Append the results to the DataFrame using concat\n",
    "results = pd.concat([results, new_results], ignore_index=True)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "results.to_excel(\"PIC1vsPIC2.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
